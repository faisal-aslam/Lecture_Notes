\section{Introduction to Data Compression}
\subsection{Learning Objectives}

\subsection{Introduction and Motivation: Why Compress Data?}
Data compression is the process of encoding information using fewer bits than the original representation. Every day, we encounter compression without realizing it: from streaming videos to sending emails, from saving photos to downloading software updates.

\begin{definitionbox}
\textbf{Data Compression}: The process of reducing the number of bits needed to represent information, while either:
\begin{itemize}
    \item \textbf{Lossless}: Preserving all original information exactly
    \item \textbf{Lossy}: Accepting some controlled loss of information for higher compression
\end{itemize}
\end{definitionbox}

\subsubsection{Benefits of Data Compression}
Data compression provides three key benefits that are critical in modern computing:

\begin{enumerate}
    \item \textbf{Reduce Storage Space}:
    \begin{itemize}
        \item Allows more data to be stored in the same physical space
        \item Enables archival of historical data that would otherwise be discarded
        \item Reduces hardware requirements for storage systems
    \end{itemize}

    \item \textbf{Reduce Communication Time and Bandwidth}:
    \begin{itemize}
        \item Enables faster file transfers and downloads
        \item Makes high-quality streaming (4K/8K video) practical over limited bandwidth
        \item Reduces latency in real-time applications like video conferencing and online gaming
        \item Allows IoT devices to transmit data efficiently over wireless networks
    \end{itemize}

    \item \textbf{Save Money}:
    \begin{itemize}
        \item Reduces cloud hosting costs (storage and egress fees)
        \item Lowers communication costs for data transmission
        \item Decreases capital expenditure on storage hardware
        \item Reduces energy consumption for data centers and network infrastructure
    \end{itemize}
\end{enumerate}



\subsection{Lossless vs. Lossy Compression: A Detailed Comparison}
\subsubsection{Lossless Compression: Perfect Reconstruction}
\textbf{How it works}: Exploits statistical redundancy and patterns without losing information.

\textbf{Key techniques}:
\begin{enumerate}
    \item \textbf{Entropy coding}: Assign shorter codes to frequent symbols (Huffman, Arithmetic)
    \item \textbf{Dictionary methods}: Replace repeated patterns with references (LZ77, LZ78)
    \item \textbf{Predictive coding}: Encode differences from predictions rather than raw values
\end{enumerate}

\begin{examplebox}
\textbf{Text Compression Example}: The word "compression" appears 100 times in a document.
\begin{itemize}
    \item Uncompressed: "compression" = 11 characters $\times$ 8 bits = 88 bits $\times$ 100 = 8,800 bits
    \item Compressed: Assign code "01" (2 bits) for "compression" $\rightarrow$ 2 bits $\times$ 100 = 200 bits
    \item Plus dictionary entry: "compression" = 88 bits (stored once)
    \item Total: 200 + 88 = 288 bits vs 8,800 bits $\rightarrow$ 30:1 compression!
\end{itemize}
This is essentially how LZW (used in GIF, ZIP) works.
\end{examplebox}

\subsubsection{Lossy Compression: Intelligent Approximation}
\textbf{How it works}: Removes information that is:
\begin{itemize}
    \item Imperceptible to humans (psychovisual/psychoacoustic models)
    \item Less important for the intended use
    \item Redundant beyond a certain quality threshold
\end{itemize}

\begin{examplebox}
\textbf{JPEG Image Compression - Step by Step}:
\begin{enumerate}
    \item \textbf{Color Space Conversion}: RGB to YCbCr (separates luminance from color)
    \item \textbf{Chrominance Downsampling}: Reduce color resolution (4:2:0) - humans are less sensitive to color details
    \item \textbf{Discrete Cosine Transform (DCT)}: Convert 8×8 pixel blocks to frequency domain
    \item \textbf{Quantization}: Divide frequency coefficients by quantization matrix - small high-frequency coefficients become zero
    \item \textbf{Entropy Coding}: Huffman code the results

    \textbf{Result}: Typical 10:1 to 20:1 compression with minimal visible artifacts
\end{enumerate}
\end{examplebox}

\subsubsection{When to Use Which? Decision Factors}

The choice between lossless and lossy compression depends on the acceptable level of
information loss, the nature of the data, and system constraints such as speed and storage.
Lossless compression is required whenever exact reconstruction is mandatory, whereas
lossy compression is preferred when human perception can tolerate approximations in
exchange for significantly higher compression ratios. The following table summarizes
the key decision factors commonly encountered in practice.

% Using tabularx for better table control
\begin{table}[htbp]
\centering
\begin{tabularx}{\textwidth}{|p{3.5cm}|X|X|}
\hline
\textbf{Factor} & \textbf{Choose Lossless When} & \textbf{Choose Lossy When} \\
\hline
\textbf{Fidelity Requirement} & Exact reconstruction is critical (code, financial data, legal documents) & Some quality loss is acceptable (media streaming, web images) \\
\hline
\textbf{Data Type} & Discrete data with exact values (text, databases, executables) & Continuous data with perceptual limits (images, audio, video) \\
\hline
\textbf{Compression Ratio Needed} & Moderate ratios suffice (2:1 to 10:1) & High ratios needed (10:1 to 200:1+) \\
\hline
\textbf{Processing Requirements} & Fast decompression needed, encode speed less critical & Real-time encoding/decoding needed (streaming, videoconferencing) \\
\hline
\textbf{Regulatory Constraints} & Legal/medical requirements mandate exact copies & No regulatory constraints on quality \\
\hline
\end{tabularx}
\caption{Decision Factors for Lossless vs. Lossy Compression}
\end{table}


\subsection{Performance Metrics: Beyond Simple Ratios}
\subsubsection{Compression Ratio and Savings}

\begin{align*}
\text{Compression Ratio} &= \frac{\text{Original Size}}{\text{Compressed Size}} \\
\text{Savings} &= \left(1 - \frac{\text{Compressed Size}}{\text{Original Size}}\right) \times 100\%
\end{align*}




\begin{examplebox}
\textbf{Comparing Different Compression Scenarios}:
\begin{center}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Scenario} & \textbf{Original} & \textbf{Compressed} & \textbf{Ratio} & \textbf{Savings} \\
\hline
Text document (ZIP) & 1.5 MB & 450 KB & 3.33:1 & 70\% \\
\hline
CD Audio (FLAC lossless) & 700 MB & 350 MB & 2:1 & 50\% \\
\hline
Same Audio (MP3 128kbps) & 700 MB & 112 MB & 6.25:1 & 84\% \\
\hline
4K Video (H.265) & 100 GB & 2 GB & 50:1 & 98\% \\
\hline
DNA sequence (specialized) & 3 GB & 300 MB & 10:1 & 90\% \\
\hline
\end{tabular}
\end{center}
\end{examplebox}

\subsubsection{Bit-rate: The Quality Control Knob}

In \textbf{lossy compression}, bit-rate is the \textbf{primary control over quality}.

\medskip

\textbf{Definition.}
Bit-rate specifies \emph{how many bits the encoder is allowed to use to represent the signal}.

\[
\boxed{
\text{Bit-rate}
=
\frac{\text{Total compressed bits}}{\text{time (seconds)}}
\quad
\text{or}
\quad
\frac{\text{Total compressed bits}}{\text{number of samples}}
}
\]

In simple terms:
\begin{quote}
\emph{Bit-rate is the number of bits spent to describe one second (or one sample) of audio or video.}
\end{quote}

\medskip

\textbf{What bit-rate really means}

\begin{itemize}
    \item \textbf{Higher bit-rate}
    $\rightarrow$ more bits available
    $\rightarrow$ less information discarded
    $\rightarrow$ higher quality, larger file

    \item \textbf{Lower bit-rate}
    $\rightarrow$ fewer bits available
    $\rightarrow$ more information discarded
    $\rightarrow$ lower quality, smaller file
\end{itemize}

Thus, bit-rate acts like a \textbf{quality dial}:

\begin{center}
Low bit-rate $\;\longrightarrow\;$ more compression $\;\longrightarrow\;$ lower quality \\
High bit-rate $\;\longrightarrow\;$ less compression $\;\longrightarrow\;$ higher quality
\end{center}

\medskip

\textbf{Why bit-rate matters mainly for lossy compression}

\begin{itemize}
    \item In \textbf{lossless compression}, the bit-rate is determined by the data itself and cannot be freely chosen.
    \item In \textbf{lossy compression}, the encoder deliberately discards information to meet a \textbf{target bit-rate}.
\end{itemize}

Therefore, in lossy systems, bit-rate is a \textbf{design parameter}, not a fixed property of the source.

\begin{examplebox}
\textbf{Audio quality at different bit-rates}

For compressed music (e.g., MP3, AAC):

\begin{itemize}
    \item \textbf{32 kbps}: Very low quality, suitable mainly for speech
    \item \textbf{96 kbps}: Acceptable quality (FM-radio–like)
    \item \textbf{128 kbps}: Good quality for most listeners
    \item \textbf{192 kbps}: Near-CD quality for most people
    \item \textbf{320 kbps}: Essentially transparent for almost all listeners
\end{itemize}

\medskip

\textbf{Storage impact for a 60-minute album}

\begin{itemize}
    \item 128 kbps $\rightarrow$ $\approx 60$ MB
    \item 320 kbps $\rightarrow$ $\approx 144$ MB
    \item FLAC (lossless) $\rightarrow$ $\approx 400$ MB
    \item Uncompressed CD audio $\rightarrow$ $\approx 700$ MB
\end{itemize}
\end{examplebox}

\medskip

\textbf{Key intuition}

\begin{quote}
\emph{Bit-rate does not measure how much information the original signal contains; it measures how much information we choose to keep.}
\end{quote}

\medskip

\textbf{One-sentence takeaway}

\begin{quote}
\emph{Bit-rate specifies how many bits per second the encoder may use, directly trading file size for perceptual quality in lossy compression.}
\end{quote}


\begin{examplebox}
\textbf{Audio Quality at Different Bit-rates}:
\begin{itemize}
    \item \textbf{32 kbps}: Telephone quality, speech only
    \item \textbf{96 kbps}: FM radio quality
    \item \textbf{128 kbps}: "Good enough" for most listeners
    \item \textbf{192 kbps}: Near CD quality for most people
    \item \textbf{320 kbps}: Essentially transparent (FLAC: ~900 kbps)

    \textbf{Storage impact}: A 60-minute album:
    \begin{itemize}
        \item At 128 kbps: 60 MB
        \item At 320 kbps: 144 MB
        \item FLAC lossless: ~400 MB
        \item Uncompressed CD: 700 MB
    \end{itemize}
\end{itemize}
\end{examplebox}

\subsubsection{Time and Space Trade-offs}
Compression involves multiple competing objectives:
\[
\text{Space--Time Trade-off} =
\frac{\text{Compression Ratio}}{\text{Encoding Time} \times \text{Decoding Time}}
\]

While higher compression ratios reduce storage and bandwidth, they often come at the cost
of increased computational complexity and latency. In real-time and large-scale streaming
systems (e.g., Netflix, YouTube, Facebook), \textbf{encoding and especially decoding speed
are often more critical than optimal compression ratios}. Streaming workloads require
fast, low-latency decoding on a wide range of devices, from mobile phones to smart TVs,
where CPU, memory, and power budgets are limited.

As a result, practical streaming systems favor compressors that achieve a \emph{good enough}
compression ratio while providing high throughput, low memory usage, and predictable
latency, even if better compression is theoretically possible.

\subsubsection{Real-World Motivation: A Concrete Example}

Consider a typical smartphone photo with the following properties:
\begin{itemize}
    \item Resolution: 12 megapixels $= 12{,}000{,}000$ pixels
    \item Color depth: 24-bit color (8 bits per RGB channel)
\end{itemize}

\paragraph{Uncompressed Image Size}

\[
\begin{aligned}
\text{Total bits} 
&= 12{,}000{,}000 \text{ pixels} \times 24 \text{ bits/pixel} \\
&= 288{,}000{,}000 \text{ bits}
\end{aligned}
\]

\[
\begin{aligned}
\text{Total bytes}
&= \frac{288{,}000{,}000}{8} \\
&= 36{,}000{,}000 \text{ bytes}
\end{aligned}
\]

\[
\begin{aligned}
\text{Size in MiB}
&= \frac{36{,}000{,}000}{1{,}048{,}576} \\
&\approx 34.33 \text{ MiB}
\end{aligned}
\]

Thus, an uncompressed photo occupies approximately $\mathbf{34.3}$~MiB.

\paragraph{Compressed Size and Compression Ratio}

In practice, the same photo is stored as a JPEG file of approximately $2.5$--$3.5$~MiB.  
Taking $3$~MiB as a representative size:

\[
\text{Compression ratio}
= \frac{34.3}{3}
\approx 11.4{:}1
\]

This lies within the typical range of $10{:}1$ to $14{:}1$ for JPEG compression.

\paragraph{Impact on Storage}

Assume a smartphone with $128$~GiB of storage:
\[
128 \text{ GiB} = 128 \times 1{,}024^3 = 137{,}438{,}953{,}472 \text{ bytes}
\]

\textbf{Uncompressed photos:}
\[
\begin{aligned}
\text{Number of photos}
&= \frac{128 \times 1{,}024^3}{34.3 \times 1{,}024^2} \\
&= \frac{128 \times 1{,}024}{34.3} \\
&\approx 3{,}817 \text{ photos}
\end{aligned}
\]

\textbf{Compressed photos (3 MiB each):}
\[
\begin{aligned}
\text{Number of photos}
&= \frac{128 \times 1{,}024^3}{3 \times 1{,}024^2} \\
&= \frac{128 \times 1{,}024}{3} \\
&\approx 43{,}691 \text{ photos}
\end{aligned}
\]

\paragraph{Impact on Communication}

Assume an upload speed of $10$~Mbps (megabits per second).

\textbf{Uncompressed photo:}
\[
\begin{aligned}
\text{Upload time}
&= \frac{34.3 \text{ MiB} \times 8}{10} \\
&= \frac{274.4}{10} \\
&\approx 27.4 \text{ seconds}
\end{aligned}
\]

\textbf{Compressed photo (3 MiB):}
\[
\begin{aligned}
\text{Upload time}
&= \frac{3 \times 8}{10} \\
&= 2.4 \text{ seconds}
\end{aligned}
\]

\paragraph{Impact on Cloud Storage Cost}

Assume cloud storage pricing of \$0.023 per GB per month.

\textbf{Uncompressed photo:}
\[
\begin{aligned}
34.3 \text{ MiB}
&= \frac{34.3}{1{,}024} \text{ GiB}
\approx 0.0335 \text{ GiB}
\end{aligned}
\]

\[
\begin{aligned}
\text{Monthly cost}
&= 0.0335 \times 0.023 \\
&\approx \$0.00077 \text{ per photo}
\end{aligned}
\]

\textbf{Compressed photo (3 MiB):}
\[
\begin{aligned}
3 \text{ MiB}
&= \frac{3}{1{,}024} \text{ GiB}
\approx 0.00293 \text{ GiB}
\end{aligned}
\]

\[
\begin{aligned}
\text{Monthly cost}
&= 0.00293 \times 0.023 \\
&\approx \$0.000067 \text{ per photo}
\end{aligned}
\]

\paragraph{Conclusion}

This example demonstrates that compression reduces storage requirements, transmission time, and monetary cost by more than an order of magnitude, making large-scale multimedia systems practical.


\begin{examplebox}
\textbf{Real-world Compressor Comparison}:
\begin{center}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Algorithm} & \textbf{Ratio (text)} & \textbf{Encode Speed} & \textbf{Decode Speed} & \textbf{Memory} \\
\hline
gzip (-6) & 3.2:1 & 100 MB/s & 400 MB/s & 10 MB \\
\hline
bzip2 (-6) & 3.8:1 & 20 MB/s & 50 MB/s & 50 MB \\
\hline
LZ4 & 2.5:1 & 500 MB/s & 2000 MB/s & 1 MB \\
\hline
Zstd (-3) & 3.0:1 & 300 MB/s & 800 MB/s & 5 MB \\
\hline
xz (-6) & 4.2:1 & 10 MB/s & 80 MB/s & 100 MB \\
\hline
\end{tabular}
\end{center}
Approximate performance on typical text data (higher is better)
\end{examplebox}

\subsection{Huffman Coding - Complete Process}

\begin{enumerate}
    \item \textbf{Modeling}: Count symbol frequencies in "ABRACADABRA"
    \begin{center}
    \begin{tabular}{|c|c|c|}
    \hline
    Symbol & Frequency & Probability \\
    \hline
    A & 5 & 5/11 $\approx$ 0.455 \\
    B & 2 & 2/11 $\approx$ 0.182 \\
    R & 2 & 2/11 $\approx$ 0.182 \\
    C & 1 & 1/11 $\approx$ 0.091 \\
    D & 1 & 1/11 $\approx$ 0.091 \\
    \hline
    \end{tabular}
    \end{center}

    \item \textbf{Coding}: Build Huffman tree (simplified):
    \begin{itemize}
        \item Combine lowest frequencies: C(1) + D(1) = CD(2)
        \item Continue combining: CD(2) + B(2) = CDB(4)
        \item Combine: CDB(4) + R(2) = CDBR(6)
        \item Final: CDBR(6) + A(5) = Root(11)
    \end{itemize}

    \item \textbf{Code assignment}:
    \begin{center}
    \begin{tabular}{|c|c|c|}
    \hline
    Symbol & Code & Length \\
    \hline
    A & 0 & 1 bit \\
    R & 10 & 2 bits \\
    B & 110 & 3 bits \\
    C & 1110 & 4 bits \\
    D & 1111 & 4 bits \\
    \hline
    \end{tabular}
    \end{center}

    \item \textbf{Compress "ABRACADABRA"}:
    \begin{itemize}
        \item A(0) B(110) R(10) A(0) C(1110) A(0) D(1111) A(0) B(110) R(10) A(0)
        \item Total bits: 1+3+2+1+4+1+4+1+3+2+1 = 23 bits
        \item Original: 11 characters $\times$ 8 bits = 88 bits
        \item Compression: 88 $\rightarrow$ 23 bits (3.8:1 ratio)
        \item Entropy limit: $H \approx 2.04$ bits/char $\times$ 11 = 22.5 bits
        \item Efficiency: 22.5/23 = 97.8\% efficient!
    \end{itemize}
\end{enumerate}



\section*{Homework Assignment}

